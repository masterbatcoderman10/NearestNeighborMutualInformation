{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nearest Neighbor Mutual Information\n",
    "\n",
    "This technique proclaims that it can successfully and accurately measure the mutual information between a continuous random variable and a discrete random variable without the use of binning. The following class implements and test this method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import digamma\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a dummy dataset\n",
    "\n",
    "This data set will comprise of x and y, y will be a continuous random variable and x will be the discrete random variable for each y point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.uniform(0, 3, (12,)).astype(np.uint16)\n",
    "y = np.array([10, 12, 14, 15, 18, 20, 21, 24, 27, 31, 33, 40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.expand_dims(x, -1)\n",
    "y = np.expand_dims(y, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.concatenate([x, y] ,axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10)\n",
      "(0, 12)\n",
      "(2, 14)\n",
      "(0, 15)\n",
      "(2, 18)\n",
      "(2, 20)\n",
      "(1, 21)\n",
      "(1, 24)\n",
      "(0, 27)\n",
      "(1, 31)\n",
      "(0, 33)\n",
      "(0, 40)\n"
     ]
    }
   ],
   "source": [
    "for x, y in t:\n",
    "    print(f\"({x}, {y})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "reds = t[:, 0] == 2\n",
    "blues = t[:, 0] == 1\n",
    "greens = t[:, 0] == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False,  True, False,  True,  True, False, False, False,\n",
       "       False, False, False])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = t[reds]\n",
    "b = t[blues]\n",
    "g = t[greens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2, 14],\n",
       "       [ 2, 18],\n",
       "       [ 2, 20]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2, 40])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_data_point = r[-1]\n",
    "selected_data_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = r[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_sub = np.sort(np.abs(rs - 10))\n",
    "kth_neighbor = rs_sub[3] + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kth_neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_point = r[r[:, 1] == 40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2, 40]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm and process to calculate mutual information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm to find the kth neighbor of a data point from the same class\n",
    "\n",
    "<ol>\n",
    "<li> Extract the data points just for that class\n",
    "<li> Create a second array which contains the sorted absolute differences between the values of the class array and the selected data point.\n",
    "<li> Choose the kth index of this array (yes the kth index and not k-1 since the first value will be 0)\n",
    "<li> Add the value of the data point to this kth value.\n",
    "<li> Pick the first data point from the class array that has this value.\n",
    "</ol>\n",
    "\n",
    "### Algorithm to find the distance m between the two data points\n",
    "<ol>\n",
    "<li> Start at the selected index in the full dataset\n",
    "<li> Move forward until the kth neighbor is found while incrementing a counter\n",
    "<li> The counter value is the value of m.\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_k(dp, k, ds):\n",
    "\n",
    "    val = dp[-1]\n",
    "    cl = ds[:, 0][0]\n",
    "    nums = ds[:, 1]\n",
    "    subs = nums - val\n",
    "    abs_subs = np.abs(subs)\n",
    "    zipped_subs = zip(subs, abs_subs)\n",
    "    zipped_subs = sorted(zipped_subs, key= lambda x: x[1])\n",
    "\n",
    "    kth_neighbor_diffs = zipped_subs[k][0]\n",
    "    kth_neighbor = np.array([cl,kth_neighbor_diffs + val])\n",
    "\n",
    "\n",
    "    return kth_neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_m(i, dp, ds):\n",
    "    \n",
    "    m = 1\n",
    "    current_dp = ds[i]\n",
    "    current_val = current_dp[1]\n",
    "    wanted_val = dp[1]\n",
    "    if current_val < wanted_val:\n",
    "        for j in range(i+1, len(ds)):\n",
    "            if np.allclose(ds[j], dp):\n",
    "                break\n",
    "            else:\n",
    "                m += 1\n",
    "    else:\n",
    "        for j in range(i-1, 0, -1):\n",
    "            if np.allclose(ds[j], dp):\n",
    "                break\n",
    "            else:\n",
    "                m += 1\n",
    "    return m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 7, 3, 5, 2, 3, 3, 2, 5, 3, 1, 3]\n",
      "0.6184884559884565\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from statistics import mean\n",
    "\n",
    "\n",
    "ms = []\n",
    "iS = []\n",
    "N = 12\n",
    "k = 2\n",
    "for i in range(len(t)):\n",
    "    \n",
    "    selected_data_point = t[i]\n",
    "    dp_class = selected_data_point[0]\n",
    "    \n",
    "    if dp_class == 0:\n",
    "        Ni = g.shape[0]\n",
    "        kth_neighbor = find_k(selected_data_point, k, g)\n",
    "    elif dp_class == 1:\n",
    "        Ni = b.shape[0]\n",
    "        kth_neighbor = find_k(selected_data_point, k, b)\n",
    "    else:\n",
    "        Ni = r.shape[0]\n",
    "        kth_neighbor = find_k(selected_data_point, k, r)\n",
    "\n",
    "    m = find_m(i, kth_neighbor, t)\n",
    "    I = digamma(N) - digamma(Ni) + digamma(k) - digamma(m)\n",
    "    iS.append(I)\n",
    "    ms.append(m)\n",
    "\n",
    "print(ms)\n",
    "print(mean(iS))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2, 21])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_k([2, 10], 2, r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_m(0, np.array([2,21]), t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the functions on a real dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = pd.read_csv(\"C:\\\\Users\\Mohammed Ali\\\\Documents\\\\Documents-Suhaib\\\\Data-Science-Projects\\\\NNMI\\\\IRIS.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width      species\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
       "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
       "4           5.0          3.6           1.4          0.2  Iris-setosa"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Iris-setosa', 'Iris-versicolor', 'Iris-virginica']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "species = list(iris.species.unique())\n",
    "species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "sepal_length = iris[[\"species\", \"sepal_length\"]].sort_values(by=[\"sepal_length\"])\n",
    "sepal_width = iris[[\"species\", \"sepal_width\"]].sort_values(by=[\"sepal_width\"])\n",
    "petal_lenght = iris[[\"species\", \"petal_length\"]].sort_values(by=[\"petal_length\"])\n",
    "petal_width = iris[[\"species\", \"petal_width\"]].sort_values(by=[\"petal_width\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_datasets = [sepal_length[sepal_length[\"species\"] == s] for s in species]\n",
    "class_dataset_2 = [sepal_width[sepal_width[\"species\"] == s] for s in species]\n",
    "class_dataset_3 = [petal_lenght[petal_lenght[\"species\"] == s] for s in species]\n",
    "class_dataset_4 = [petal_width[petal_width[\"species\"] == s] for s in species]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dict = {s:np.array(d.sort_values(by=[\"sepal_length\"])) for s,d in zip(species, class_datasets)}\n",
    "dataset_dict_2 = {s:np.array(d.sort_values(by=[\"sepal_width\"])) for s,d in zip(species, class_dataset_2)}\n",
    "dataset_dict_3 = {s:np.array(d.sort_values(by=[\"petal_length\"])) for s,d in zip(species, class_dataset_3)}\n",
    "dataset_dict_4 = {s:np.array(d.sort_values(by=[\"petal_width\"])) for s,d in zip(species, class_dataset_4)}   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNMI_Helper:\n",
    "\n",
    "    def __init__(self, discrete_name, cont_variables: list, ds: pd.DataFrame):\n",
    "\n",
    "        self.discrete_name = discrete_name\n",
    "        self.cont_variables = cont_variables\n",
    "        self.ds = ds\n",
    "        self.class_vars = list(ds[discrete_name].unique())\n",
    "    \n",
    "    #This method extracts a discrete-continuous variable pair dataframe from the overall dataset, returns all such pairings\n",
    "    def extract_subset(self):\n",
    "\n",
    "        sub_ds = [self.ds[[self.discrete_name, cont_name]].sort_values(by = [cont_name]) for cont_name in self.cont_variables]\n",
    "        return sub_ds\n",
    "\n",
    "    def calculate_intermediate(self, sub_datasets):\n",
    "\n",
    "        intermediate_datasets = [[sub_ds[sub_ds[self.discrete_name] == class_var] for class_var in self.class_vars] for sub_ds in sub_datasets]\n",
    "        return intermediate_datasets\n",
    "    \n",
    "    def make_dataset_dicts(self, intermediate_datasets):\n",
    "        \n",
    "        all_dataset_dicts = []\n",
    "\n",
    "        for cont_var, id in zip(self.cont_variables, intermediate_datasets):\n",
    "            inter_dict = {}\n",
    "            for s, sub_cd in zip(self.class_vars, id):\n",
    "                inter_dict[s] = np.array(sub_cd.sort_values(by=[cont_var]))\n",
    "\n",
    "            all_dataset_dicts.append(inter_dict)\n",
    "\n",
    "\n",
    "              \n",
    "        return all_dataset_dicts\n",
    "\n",
    "    def process(self):\n",
    "\n",
    "        sub_datasets = self.extract_subset()\n",
    "        intermediate_datasets = self.calculate_intermediate(sub_datasets)\n",
    "        ds_dicts   = self.make_dataset_dicts(intermediate_datasets)\n",
    "\n",
    "        return {c: (subds, dd) for (c, subds , dd) in zip(self.cont_variables, sub_datasets, ds_dicts)}\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NearestNeighborMutualInformation:\n",
    "\n",
    "    def __init__(self, k, data, class_dict):\n",
    "        self.data = np.array(data)\n",
    "        self.class_dict = class_dict\n",
    "        self.k = k\n",
    "    \n",
    "    def find_k(self, dp, k, ds):\n",
    "\n",
    "        val = dp[-1]\n",
    "        cl = ds[:, 0][0]\n",
    "        nums = ds[:, 1]\n",
    "        subs = nums - val\n",
    "        abs_subs = np.abs(subs)\n",
    "        zipped_subs = zip(subs, abs_subs)\n",
    "        zipped_subs = sorted(zipped_subs, key= lambda x: x[1])\n",
    "\n",
    "        kth_neighbor_diffs = zipped_subs[k][0]\n",
    "        kth_neighbor = np.array([cl,kth_neighbor_diffs + val])\n",
    "\n",
    "\n",
    "        return kth_neighbor\n",
    "\n",
    "    def find_m(self, i, dp, ds):\n",
    "        \n",
    "        m = 1\n",
    "        current_dp = ds[i]\n",
    "        current_val = float(current_dp[1])\n",
    "        wanted_val = float(dp[1])\n",
    "        if current_val < wanted_val:\n",
    "            for j in range(i+1, len(ds)):\n",
    "                if (ds[j][0] == dp[0]) and (ds[j][1] == float(dp[1])):\n",
    "                    break\n",
    "                else:\n",
    "                    m += 1\n",
    "        else:\n",
    "            for j in range(i-1, 0, -1):\n",
    "                if (ds[j][0] == dp[0]) and (ds[j][1] == float(dp[1])):\n",
    "                    break\n",
    "                else:\n",
    "                    m += 1\n",
    "        return m\n",
    "    \n",
    "    def calc_I(self, N, Ni, k, m):\n",
    "        return (digamma(N) - digamma(Ni) + digamma(k) - digamma(m))\n",
    "    \n",
    "    def calc_mi(self):\n",
    "\n",
    "        iS = []\n",
    "        N = len(self.data)\n",
    "        for i in range(N):\n",
    "            \n",
    "            selected_data_point = self.data[i]\n",
    "            dp_class = selected_data_point[0]\n",
    "\n",
    "            Ni = self.class_dict[dp_class].shape[0]\n",
    "            kth_neighbor = self.find_k(selected_data_point, self.k, self.class_dict[dp_class])\n",
    "            #print(f\"k: {kth_neighbor}\")\n",
    "            m = self.find_m(i, kth_neighbor, self.data)\n",
    "            #print(f\"datapoint: {selected_data_point}\")\n",
    "            #print(N, Ni, m)\n",
    "            I = self.calc_I(N, Ni, k, m)\n",
    "            iS.append(I)\n",
    "        return np.mean(iS)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNMI_Aggregator:\n",
    "\n",
    "    def __init__(self, data, k, disc_name):\n",
    "        \n",
    "        self.data = data\n",
    "        self.scores = {}\n",
    "        self.keys = data.keys()\n",
    "        self.k = k\n",
    "        self.disc_name = disc_name\n",
    "\n",
    "    def process_scores(self, print_mode = False):\n",
    "\n",
    "        for key in self.keys:\n",
    "            cont_data, cont_dict = self.data[key]\n",
    "            nnmi = NearestNeighborMutualInformation(self.k, cont_data, cont_dict)\n",
    "            self.scores[key] = nnmi.calc_mi()\n",
    "            if print_mode:\n",
    "                print(f\"The mutual information of the continuous variable {key} with {self.disc_name} is {self.scores[key]}\")\n",
    "            else:\n",
    "                continue\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnmi_helper = NNMI_Helper(\"species\", [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"], iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = nnmi_helper.process()\n",
    "petal_width, pw_dict = data[\"petal_width\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnmi_agg = NNMI_Aggregator(data, 3, \"species\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mutual information of the continuous variable sepal_length with species is 0.8363259854789786\n",
      "The mutual information of the continuous variable sepal_width with species is 0.6837603255555182\n",
      "The mutual information of the continuous variable petal_length with species is 1.3760477676104501\n",
      "The mutual information of the continuous variable petal_width with species is 1.4680088431523317\n"
     ]
    }
   ],
   "source": [
    "nnmi_agg.process_scores(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the results of Nearest Neighbor Mutual Information with the iris dataset\n",
    "\n",
    "The following code section will fit decision trees on different datasets, one with all the data, one with the two variables which have a lower mutual information with the species, and one with the two variables which have a higher mutual information with the species. The decision trees will then be evaluated against test data to measure the performance which will therefore show whether the nearest neighbor mutual information works correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X = df.drop(['target'],axis=1).values   # independant features\n",
    "# y = df['target'].values\t\t\t\t\t# dependant variable\n",
    "\n",
    "# # Choose your test size to split between training and testing sets:\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Decision Tree trained on all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.drop([\"species\"], axis = 1).values\n",
    "y = iris[\"species\"].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_1  = DecisionTreeClassifier()\n",
    "dt_1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_1.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With all the data passed into the classifier, it returns a test accuracy of 0.97 which is already incredibly high."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Decision Tree trained on the variables with low mutual information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris[[\"sepal_length\", \"sepal_width\"]].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_2 = DecisionTreeClassifier()\n",
    "dt_2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_2.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the independent variables with low mutual information has resulted in a low test accuracy of 66%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Testing with the variables with the highest mutual information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris[[\"petal_length\", \"petal_width\"]].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_3 = DecisionTreeClassifier()\n",
    "dt_3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_3.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When trained on the independent variables which showed high mutual information with the response variable, the test accuracy of the model is the highest with a test accuracy of 99% on average, this is slightly higher than training the model on all the independent variables.\n",
    "\n",
    "While the dataset was quite small, these results show that nearest neighbor mutual information can be applied successfully to a dataset to choose only those independent variables which will result in maximal learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9cbd400ed05db1546209cf0ce449d447a50b69d60697d23e48a62ee68cf2bbaf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
